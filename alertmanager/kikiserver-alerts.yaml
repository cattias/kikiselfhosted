apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kikiserver-critical-alerts
  namespace: monitoring
  labels:
    release: kube-prometheus-stack
spec:
  groups:
  - name: kikiserver.alerts
    rules:
    - alert: KubePodCrashLooping
      expr: |
        count(kube_pod_container_status_restarts_total) by (pod, namespace) > 5
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} is crashlooping ({{ $value }} restarts).
        description: Check logs for application errors.

    - alert: KubePersistentVolumeFillingUp
      expr: |
        (kubelet_volume_stats_available_bytes{job="kubelet"} / kubelet_volume_stats_capacity_bytes{job="kubelet"} * 100) < 10 and kubelet_volume_stats_used_bytes{job="kubelet"} > 0
      for: 15m
      labels:
        severity: warning
      annotations:
        summary: Persistent Volume {{ $labels.persistentvolumeclaim }} is filling up ({{ $value }}% remaining).
        description: PVC is running out of space. Check your disk capacity.

    - alert: CephClusterHealthDegraded
      # The 'ceph_health_status' metric reports 0 for HEALTH_OK.
      # This expression fires if the status is anything but 0.
      expr: |
        ceph_health_status != 0
      
      # The alert will fire immediately (for: 0m) as soon as the status changes.
      for: 0m
      
      labels:
        severity: critical
        team: storage
        
      annotations:
        summary: "ðŸ›‘ CEPH HEALTH STATUS CHANGE: Cluster is no longer HEALTH_OK"
        description: "The top-level Ceph health metric changed from 0 (OK) to {{ $value }}. Check the Ceph dashboard immediately for specific warnings (e.g., OSDs down, PGs degraded). The change indicates a cluster-wide issue."